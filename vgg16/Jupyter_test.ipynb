{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 13:43:09.606764: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1226, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 13:43:17.175886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:17.302142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:17.302229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:17.307023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 13:43:17.313888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:17.313957: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:17.313990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:19.876912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:19.877090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:19.877120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-23 13:43:19.877202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-23 13:43:19.877599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3417 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 13:43:24.267588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n",
      "2023-03-23 13:43:31.474017: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:31.475118: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:32.630591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-23 13:43:32.658587: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1cd51a40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-23 13:43:32.658662: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-03-23 13:43:32.697303: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-23 13:43:33.082364: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 135.3638 - accuracy: 0.2812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 13:43:34.973317: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:34.973459: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:35.108011: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:35.108083: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:35.218246: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:35.218336: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:35.322493: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-23 13:43:35.322637: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 565ms/step - loss: 135.3638 - accuracy: 0.2812 - val_loss: 68.9708 - val_accuracy: 0.4589\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 2s 626ms/step - loss: 54.9787 - accuracy: 0.3276 - val_loss: 37.9144 - val_accuracy: 0.3288\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 21.0786 - accuracy: 0.4375 - val_loss: 19.6715 - val_accuracy: 0.4863\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 10.5031 - accuracy: 0.5000 - val_loss: 11.3489 - val_accuracy: 0.4384\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 328ms/step - loss: 8.4851 - accuracy: 0.5938 - val_loss: 10.5063 - val_accuracy: 0.6233\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 9.0923 - accuracy: 0.5938 - val_loss: 9.2886 - val_accuracy: 0.5342\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 325ms/step - loss: 5.4601 - accuracy: 0.6562 - val_loss: 7.8428 - val_accuracy: 0.6301\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 3.8882 - accuracy: 0.7500 - val_loss: 6.9949 - val_accuracy: 0.6438\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 3.0025 - accuracy: 0.7344 - val_loss: 6.0806 - val_accuracy: 0.5137\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 366ms/step - loss: 1.3669 - accuracy: 0.8281 - val_loss: 3.4075 - val_accuracy: 0.6644\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "# To load a file use the format [/mnt/c/path/to/file]\n",
    "# data = np.load(r'/mnt/c/Users/John/Documents/Datasets/task7/task7_X_train.npy')\n",
    "x_train = np.load(r\"/mnt/c/Windows/System32/repos/thesis_raw_data/task5/task5_X_train.npy\")\n",
    "y_train = np.load(r\"/mnt/c/Windows/System32/repos/thesis_raw_data/task5/task5_y_train.npy\")\n",
    "\n",
    "x_test = np.load(r\"/mnt/c/Windows/System32/repos/thesis_raw_data/task5/task5_X_test.npy\")\n",
    "y_test = np.load(r\"/mnt/c/Windows/System32/repos/thesis_raw_data/task5/task5_y_test.npy\")\n",
    "print(x_train.shape)\n",
    "\n",
    "vgg16_model = VGG16(include_top = False,\n",
    "            weights = 'imagenet', \n",
    "            input_tensor = None, \n",
    "            input_shape = (224,224,3), #shape of npy file data\n",
    "            pooling = None,\n",
    "            classes = 1000,\n",
    "            classifier_activation=\"softmax\") \n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "# Do not retrain convolutional layers\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "input_shape = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "# Add new fully connected layers\n",
    "x = Flatten()(vgg16_model.output)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)  # num_classes is the number of classes in your dataset\n",
    "\n",
    "# Create a new model with the fully connected layers added\n",
    "model = Model(inputs=vgg16_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create an instance of ImageDataGenerator for data augmentation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m datagen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m      3\u001b[0m                             \u001b[39m#  rotation_range=20,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                             \u001b[39m#  width_shift_range=0.1,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                             \u001b[39m#  height_shift_range=0.1,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                             \u001b[39m#  shear_range=0.2,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                             \u001b[39m#  zoom_range=0.2,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                             \u001b[39m#  horizontal_flip=True\u001b[39;00m\n\u001b[1;32m      9\u001b[0m                              )\n\u001b[1;32m     11\u001b[0m \u001b[39m# Fit the ImageDataGenerator on the training data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m datagen\u001b[39m.\u001b[39mfit(x_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "                            #  rotation_range=20,\n",
    "                            #  width_shift_range=0.1,\n",
    "                            #  height_shift_range=0.1,\n",
    "                            #  shear_range=0.2,\n",
    "                            #  zoom_range=0.2,\n",
    "                            #  horizontal_flip=True\n",
    "                             )\n",
    "\n",
    "# Fit the ImageDataGenerator on the training data\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Create generators for the training and validation data\n",
    "train_generator = datagen.flow(x_train,\n",
    "                               y_train, \n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True\n",
    "                               )\n",
    "                               \n",
    "test_generator = datagen.flow(x_test, \n",
    "                              y_test, \n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "# Use the generators to train the model\n",
    "history = model.fit(train_generator,\n",
    "          epochs=num_epochs,\n",
    "          steps_per_epoch= len(train_generator) // batch_size,\n",
    "          validation_data=test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('vgg16_trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Plot the training and validation accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel Accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "print(history.history['val_accuracy'])\n",
    "#Find the x and y position of the highest test accuracy\n",
    "#list all val_accuracy values\n",
    "list = history.history['val_accuracy']\n",
    "\n",
    "#find highest val_accuracy\n",
    "ymax =  max(history.history['val_accuracy'])\n",
    "\n",
    "#find index of highest val_accuracy\n",
    "xpos = list.index(max(history.history['val_accuracy']))\n",
    "\n",
    "# Annotation for max accuracy\n",
    "plt.annotate('Max Accuracy @ {}%'.format(round(ymax*100,2)), xy=(xpos, ymax), xytext=(xpos, ymax+.05), ha = 'center', \n",
    "             arrowprops=dict(arrowstyle=\"->\", facecolor='black'))\n",
    "#Show plot             \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
